---
title: "sPLS-DA Initial Script"
output:
  html_document:
    df_print: paged
---

```{r}

# MixOmics not available through CRAN, but we can do this:

#if (!requireNamespace("BiocManager", quietly = TRUE))
   # install.packages("BiocManager")

#BiocManager::install("mixOmics")

```

```{r}
#loading relevent libraries. 
library("mixOmics")
library("readr")
library(tidyverse)
library(pROC)


```

## 1: Reading in Data

We will begin our sPLS-DA model by loading in relevant datasets from the Guo *et al* (2023) paper outlining the microbial differences in HFM diseased and healthy control patients.

Our initial data will consist of the following files - ASV_table (ASVtable.csv) - ASV_RDP association (RDP.csv) - genus, phylum, order etc. abundance (\_.csv) - Two metadata files (metadata1.csv metadata2.csv)

```{r}
ASV_table<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/ASVtable.csv")
ASV_RDP<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/RDP.csv")
genus<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/genus.csv")
phylum<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/phylum.csv")
order<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/order.csv")
class<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/class.csv")
family<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/family.csv")
meta1<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/metadata1.csv")
meta2<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/metadata2.csv")

```

## 2: Data Preperation

This following section is to check and prepare the data for analysis.

```{r}
#lets check for missing values
sum(is.na(ASV_table))
sum(is.na(ASV_RDP))
sum(is.na(genus))
sum(is.na(phylum))
sum(is.na(class))
sum(is.na(family))
sum(is.na(meta1))
sum(is.na(meta2))
```

```{r}
meta1 <- meta1[-(0:5), ]
meta2 <- meta2[-(0:5), ]
#lets remove top 5 rows to make data handling nicer
# column headings are wrong, lets fix it here:
colnames(meta1) <- as.character(meta1[1, ])
meta1 <- meta1[-1, ]

colnames(meta2) <- as.character(meta2[1, ])
meta2 <- meta2[-1, ]
```

```{r}
# We will now remove the first column and see if the data we gathered from FigShare has been normalized using the row_sums function. As we can see from the output it is not normalized. 
asv_table_numeric1 <- ASV_table[,-1] 

row_sums <- rowSums(asv_table_numeric1)
print(row_sums)
```

```{r}
# We will now normalize the data by relative abundance, to equalize sequencing depth. 
# The ID column ("X.OTUID") is causing problems for normalization. We will remove it and add it in later. 

# Select all columns except 'X.OTUID' for normalization.
asv_table_numeric <- ASV_table[ , -which(names(ASV_table) %in% "X.OTUID")]

# Normalize only the selected columns.
asv_table_normalized <- t(apply(asv_table_numeric, 1, function(x) x / sum(x)))

# Check row sums.
row_sums2 <- rowSums(asv_table_normalized)
print(row_sums2)

# Looks like our data is now normalized. We can now proceed to add in our ID column back in the dataframe, and then continue our analysis. 
```

```{r}
# Add back 'X.OTUID' to the normalized dataframe.
asv_table_normalized <- as.data.frame(asv_table_normalized)

asv_table_normalized$X.OTUID <- ASV_table$X.OTUID

x_otuid_index <- match("X.OTUID", names(asv_table_normalized))

asv_table_normalized <- asv_table_normalized[, c(x_otuid_index, setdiff(1:ncol(asv_table_normalized), x_otuid_index))]
```

```{r}
#Checking the data structure from the un-transformed dataset to make sure it is the same as our new dataset. If there were deletions, then applying the ID column as shown above would result in incorrect ordering. 

str(ASV_table)
str(asv_table_normalized)

# It looks like we are OK to proceed. 
```

```{r}
# We can now merge the metadata with the ASV table. 

# Convert the ASV dataframe to a long format
asv_data_long <- asv_table_normalized %>%
  pivot_longer(-X.OTUID, names_to = "SampleNum", values_to = "ASV_Count")

# Pivot the long format dataframe to wide format
asv_data_wide <- asv_data_long %>%
  pivot_wider(names_from = "X.OTUID", values_from = "ASV_Count")

# Remove the row names
rownames(asv_data_wide) <- NULL

# Rename the first column to "SampleNum"
colnames(asv_data_wide)[1] <- "SampleNum"

# View the transformed dataframe
head(asv_data_wide)
str(asv_data_wide)

# OK. Data looks good. We can now proceed to link to the metadata. 
```

```{r}
# For the PLS-DA analysis we will take the "control" and "HFM" labels as the main elements of the discriminant analysis. In the following code, I will link the metadata to the sample numbers, and use a binary system to label each sample number as either "healthy" or "HFM". 

merged_data <- merge(asv_data_wide, meta2[, c("SampleID", "Group")], by.x = "SampleNum", by.y = "SampleID")
merged_data$Status <- ifelse(merged_data$Group == "Control", 1, 0)
asv_columns <- grep("^ASV", colnames(merged_data), value = TRUE)
selected_columns <- c("SampleNum", asv_columns, "Status")
merged_data <- merged_data[, selected_columns]
merged_data <- merged_data[, c("SampleNum", "Status", setdiff(colnames(merged_data), c("SampleNum", "Status")))]

#Some extra steps above to allow us to validate the "Status" column to make sure the binary designation is correct. It looks good so far. 

```

## 3. sPLS-DA Model

```{r}
# We can now begin with the actual sPLS-DA model, as we now have a perfect dataset to get started. 

# Extract X (ASV data)
X <- merged_data[, -(1:2)]

# Extract Y (Status)
Y <- merged_data$Status

# Run sPLS-DA
# Split data into training and testing sets
set.seed(123)  # Set seed for reproducibility, so that we can have consistent results below. 
train_indices <- sample(1:nrow(X), nrow(X) * 0.8)  # Generate random indices for training data
X_train <- X[train_indices, ]
Y_train <- Y[train_indices]
X_test <- X[-train_indices, ]
Y_test <- Y[-train_indices]

# Fit the sPLS-DA model on training data
splsda <- splsda(X_train, Y_train, ncomp = 2)
## Running into trouble varying ncomp (eg 1), will need to look into this further. 

# Predict individual sample scores on testing data
indiv_scores_test <- predict(splsda, newdata = X_test, type = "scores")

# Extract the component 1 scores from indiv_scores_test
scores_comp1 <- indiv_scores_test$X.test$comp1


```

```{r}
plotIndiv(splsda, Group = Y, legend = TRUE, ellipse =TRUE, title = "sPLS-DA", )

# Very interesting result. As defined earlier, 0 is HFM, and 1 is Control. Looks like there is a meaningful difference between the two groups.

```

```{r}

# We can now compute the AUC for the model to see the quality of the model. 

# Extract the predicted scores and true class labels
predicted_scores <- indiv_scores_test$predict
true_labels <- as.numeric(Y_test) - 1  # Convert factor levels to numeric (0, 1)

# Compute AUC for each component and average them
auc_values <- sapply(1:2, function(comp) {
  roc_obj <- roc(true_labels, predicted_scores[, comp, 2])
  auc(roc_obj)
})

# Average AUC across components
average_auc <- mean(auc_values)

# Print the AUC
cat("Average AUC:", average_auc, "\n")


# From what I see online and in the airways paper, this looks like a pretty good score. Model looks good (?). 

```

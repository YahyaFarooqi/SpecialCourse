---
title: "sPLS-DA Initial Script"
output:
  html_document:
    df_print: paged
---

```{r}

# MixOmics not available through CRAN, but we can do this:

#if (!requireNamespace("BiocManager", quietly = TRUE))
   # install.packages("BiocManager")

#BiocManager::install("mixOmics")

```

```{r}
#loading relevent libraries. 
library("mixOmics")
library("readr")
library(tidyverse)
library(pROC)


```

## 1: Reading in Data

We will begin our sPLS-DA model by loading in relevant datasets from the Guo *et al* (2023) paper outlining the microbial differences in HFM diseased and healthy control patients.

Our initial data will consist of the following files - ASV_table (ASVtable.csv) - ASV_RDP association (RDP.csv) - genus, phylum, order etc. abundance (\_.csv) - Two metadata files (metadata1.csv metadata2.csv)

```{r}
ASV_table<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/ASVtable.csv")
ASV_RDP<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/RDP.csv")
genus<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/genus.csv")
phylum<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/phylum.csv")
order<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/order.csv")
class<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/class.csv")
family<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/family.csv")
meta1<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/metadata1.csv")
meta2<- read.csv("/Users/nfarooqi/Downloads/Rebi/HFM/csv/metadata2.csv")

```

## 2: Data Preperation

This following section is to check and prepare the data for analysis.

```{r}
#lets check for missing values
sum(is.na(ASV_table))
sum(is.na(ASV_RDP))
sum(is.na(genus))
sum(is.na(phylum))
sum(is.na(class))
sum(is.na(family))
sum(is.na(meta1))
sum(is.na(meta2))
```

```{r}
meta1 <- meta1[-(0:5), ]
meta2 <- meta2[-(0:5), ]
#lets remove top 5 rows to make data handling nicer
# column headings are wrong, lets fix it here:
colnames(meta1) <- as.character(meta1[1, ])
meta1 <- meta1[-1, ]

colnames(meta2) <- as.character(meta2[1, ])
meta2 <- meta2[-1, ]
```

```{r}
# We will now remove the first column and see if the data we gathered from FigShare has been normalized using the row_sums function. As we can see from the output it is not normalized. 
asv_table_numeric1 <- ASV_table[,-1] 

row_sums <- rowSums(asv_table_numeric1)
print(row_sums)
```

```{r}
# We will now normalize the data by relative abundance, to equalize sequencing depth. 
# The ID column ("X.OTUID") is causing problems for normalization. We will remove it and add it in later. 

# Select all columns except 'X.OTUID' for normalization.
asv_table_numeric <- ASV_table[ , -which(names(ASV_table) %in% "X.OTUID")]

# Normalize only the selected columns.
asv_table_normalized <- t(apply(asv_table_numeric, 1, function(x) x / sum(x)))

# Check row sums.
row_sums2 <- rowSums(asv_table_normalized)
print(row_sums2)

# Looks like our data is now normalized. We can now proceed to add in our ID column back in the dataframe, and then continue our analysis. 
```

```{r}
# Add back 'X.OTUID' to the normalized dataframe.
asv_table_normalized <- as.data.frame(asv_table_normalized)

asv_table_normalized$X.OTUID <- ASV_table$X.OTUID

x_otuid_index <- match("X.OTUID", names(asv_table_normalized))

asv_table_normalized <- asv_table_normalized[, c(x_otuid_index, setdiff(1:ncol(asv_table_normalized), x_otuid_index))]
```

```{r}
#Checking the data structure from the un-transformed dataset to make sure it is the same as our new dataset. If there were deletions, then applying the ID column as shown above would result in incorrect ordering. 

str(ASV_table)
str(asv_table_normalized)

# It looks like we are OK to proceed. 
```

```{r}
# We can now merge the metadata with the ASV table. 

# Convert the ASV dataframe to a long format
asv_data_long <- asv_table_normalized %>%
  pivot_longer(-X.OTUID, names_to = "SampleNum", values_to = "ASV_Count")

# Pivot the long format dataframe to wide format
asv_data_wide <- asv_data_long %>%
  pivot_wider(names_from = "X.OTUID", values_from = "ASV_Count")

# Remove the row names
rownames(asv_data_wide) <- NULL

# Rename the first column to "SampleNum"
colnames(asv_data_wide)[1] <- "SampleNum"

# View the transformed dataframe
head(asv_data_wide)
str(asv_data_wide)

# OK. Data looks good. We can now proceed to link to the metadata. 
```

```{r}
# For the PLS-DA analysis we will take the "control" and "HFM" labels as the main elements of the discriminant analysis. In the following code, I will link the metadata to the sample numbers, and use a binary system to label each sample number as either "healthy" or "HFM". 

merged_data <- merge(asv_data_wide, meta2[, c("SampleID", "Group")], by.x = "SampleNum", by.y = "SampleID")
merged_data$Status <- ifelse(merged_data$Group == "Control", 1, 0)
asv_columns <- grep("^ASV", colnames(merged_data), value = TRUE)
selected_columns <- c("SampleNum", asv_columns, "Status")
merged_data <- merged_data[, selected_columns]
merged_data <- merged_data[, c("SampleNum", "Status", setdiff(colnames(merged_data), c("SampleNum", "Status")))]

#Some extra steps above to allow us to validate the "Status" column to make sure the binary designation is correct. It looks good so far. 

```

## 3. sPLS-DA Model

```{r}
# We can now begin with the actual sPLS-DA model, as we now have a perfect dataset to get started. 

# Extract X (ASV data)
X <- merged_data[, -(1:2)]

# Extract Y (Status)
Y <- merged_data$Status

# Run sPLS-DA
# Split data into training and testing sets
set.seed(123)  # Set seed for reproducibility, so that we can have consistent results below. 
train_indices <- sample(1:nrow(X), nrow(X) * 0.8)  # Generate random indices for training data
X_train <- X[train_indices, ]
Y_train <- Y[train_indices]
X_test <- X[-train_indices, ]
Y_test <- Y[-train_indices]

# Fit the sPLS-DA model on training data (1 component)
splsda <- splsda(X_train, Y_train, ncomp = 1)

# Predict individual sample scores on testing data
indiv_scores_test <- predict(splsda, newdata = X_test, type = "scores")

# Extract the component 1 scores from indiv_scores_test
scores_comp1 <- indiv_scores_test$predict[, , 1]



```

```{r}
#plotIndiv(splsda, Group = Y, legend = TRUE, ellipse = TRUE, title = "sPLS-DA", comp = 1)

# Very interesting result. As defined earlier, 0 is HFM, and 1 is Control. Looks like there is a meaningful difference between the two groups.

```



```{r}

# We can now compute the AUC for the model to see the quality of the model. 

# Extract the predicted scores and true class labels for the single component
predicted_scores_comp1 <- indiv_scores_test$predict[, 1, 1]
true_labels_comp1 <- as.numeric(Y_test) - 1  # Convert factor levels to numeric (0, 1)

# Compute AUC for the single component
auc_value <- roc(true_labels_comp1, predicted_scores_comp1)$auc

# Print the AUC
cat("AUC:", auc_value, "\n")


```
```{r}
rdp_reshaped <- ASV_RDP %>%
  separate("Level.of.annotation", into = c("d", "p", "c", "o", "f", "g"), sep = ",")

```
```{r}
# Get the ASV IDs from the column names in df_samples
#asv_ids <- colnames(merged_data)[-c(1:2)]  # Exclude the first two columns (SampleNum and health_status)

# Filter the relevant rows from rdp_reshaped based on the asv_ids
#filtered_rdp <- rdp_reshaped[rdp_reshaped$ASV_ID %in% asv_ids, ]

# Rename the ASV_ID column in filtered_rdp to match df_samples
#colnames(filtered_rdp)[1] <- "ASV_ID"

# Merge df_samples with filtered_rdp based on the SampleNum column
#merged3 <- left_join(merged_data, filtered_rdp, by = "SampleNum")

#failed attempt to join RDP to merged. 

```

```{r}
library(tidyverse)

# Assuming your original data frame is named df

# Convert the "Phylum" column to row names
df_with_row_names <- column_to_rownames(phylum, var = "Phylum")

# Reshape the data frame to long format
long_df <- df_with_row_names %>%
  rownames_to_column(var = "Phylum") %>%
  pivot_longer(cols = -Phylum, names_to = "SampleID", values_to = "Value")

# Assuming your data frames are named df1 and df2

# Merge the data frames based on the "samplenum" and "sampleid" columns
merged_df <- merge(merged_data, long_df, by.x = "SampleNum", by.y = "SampleID")

```


```{r}
library(ggplot2)

# Assuming you have a data frame named "phylum_values" with columns "phylum" and "values"

# Combine the sPLS-DA scores with the phylum values
scores_phylum <- cbind(scores_comp1, phylum_values)

# Convert the combined data to a data frame
df_scores_phylum <- as.data.frame(scores_phylum)

# Create the scatter plot
ggplot(df_scores_phylum, aes(x = comp1, y = comp2, color = values)) +
  geom_point() +
  labs(x = "Component 1", y = "Component 2", color = "Phylum Values") +
  scale_color_gradient(low = "blue", high = "red") +
  theme_minimal()

```










